{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Где применяется SVD?\n",
    "\n",
    "В рекомендательных системах, в сжатии матрицы без потерь, в аппроксимации матрицей меньшего ранга\n",
    "    \n",
    "2) Можно ли применить SVD для квадратичных матриц?\n",
    "\n",
    "Да\n",
    "\n",
    "3) Что описывают матрицы $U, S, V ?$\n",
    "    $$A = U S V^T$$\n",
    "    \n",
    "$U$ - ортогональная матрица левых собственных векторов $AA^T$\n",
    "\n",
    "$V$ - ортогональная матрица правых собственных векторов $A^TA$\n",
    "\n",
    "$S$ - диагональна матрица сингулярных чисел $\\sigma_{1} > \\sigma_{2} > \\dots > \\sigma_{r}$\n",
    "\n",
    "4) Какими свойствами обладает $U, S, V ?$\n",
    "    $$A_{mxn} = U_{mxm}S_{mxn}V_{nxn}^T$$\n",
    "\n",
    "5) Для чего может понадобиться усечение матрицы сингулярных чисел?\n",
    "\n",
    "Для низкорангового приближения. Таким образом получается сохранить наибольшую часть информации, задействовав меньше памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      " [[-0.94679109]\n",
      " [-0.24481854]\n",
      " [-0.03969757]\n",
      " [-0.20512097]]\n",
      "\n",
      "S\n",
      " [35.83924895]\n",
      "\n",
      "V\n",
      " [[-0.03435639 -0.04429285 -0.8883508   0.45573088]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, -1, 30, -16],\n",
    "              [1, 6, 8, -3],\n",
    "              [1, 1, 1, -1],\n",
    "              [0, 5, 7, -2]])\n",
    "\n",
    "U, S, V = np.linalg.svd(A)\n",
    "num_components = 1\n",
    "print('U\\n', U[:, :num_components])\n",
    "print('\\nS\\n', S[:num_components])\n",
    "print('\\nV\\n', V[:num_components, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усечение было произведено по первой компоненте, т. к. первая компонента вносит наибольший вклад"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.58392490e+01 7.98252206e+00 1.35187874e+00 1.76113408e-16]\n"
     ]
    }
   ],
   "source": [
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходная матрица\n",
      " [[  1  -1  30 -16]\n",
      " [  1   6   8  -3]\n",
      " [  1   1   1  -1]\n",
      " [  0   5   7  -2]]\n",
      "\n",
      "Приближенная матрица\n",
      " [[  1.16579069   1.50295755  30.14376955 -15.46398872]\n",
      " [  0.30144683   0.38863047   7.7944899   -3.99863407]\n",
      " [  0.0488799    0.06301681   1.26388416  -0.64838242]\n",
      " [  0.25256693   0.32561366   6.53060575  -3.35025165]]\n",
      "\n",
      "Норма Фробениуса\n",
      " 8.096186423027575\n"
     ]
    }
   ],
   "source": [
    "A_new = np.matrix(U[:, :num_components]) * np.diag(S[:num_components]) * np.matrix(V[:num_components, :])\n",
    "print('Исходная матрица\\n', A)\n",
    "print('\\nПриближенная матрица\\n', A_new)\n",
    "print('\\nНорма Фробениуса\\n', np.linalg.norm(np.matrix(A) - A_new, ord='fro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
